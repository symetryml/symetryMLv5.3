= Symetry Web - User Guide
:toc:
:toclevels: 2
:toc-placement: preamble
:doctype: book
// :imagesdir: .media/web

Copyright © 2020 by Symetry, Inc. +
14 Pine Street, Ste 6 +
Morristown, NJ 07960 +
All Rights Reserved +
March 30, 2021

[[introduction]]
== Introduction

This user guide is intended for analysts using SymetryML in their next
data-mining project. While this document does not assume extensive
background in data modeling, the reader should have a rudimentary
understanding of data-mining methodology, as well as the necessary
domain knowledge related to their field of application.

A brief introduction to data-mining concepts will be provided in this
guide, along with instructions on applying these concepts to SymetryML
workflow. The core intention of this document is to provide readers
with a brief summary of the information needed to implement SymetryML
successfully into their data-driven projects and to cover typical usage
scenarios.

[[related-documents]]
=== Related Documents

While this guide provides an introduction to data-mining concepts and general
guidance on navigating SymetryML Web UI, more specific guides dealing with sequence data and
Federated Learning can be found here:

* <<SML_Sequence_Projects_and_Models.adoc#>>
* <<SML_FedML_User_Guide.adoc#>>

// For a brief introduction to data-mining concepts, as well as general guidance on navigating the SymetryML Web UI, please refer to <<SML_Web_User_Guide.adoc#>>.

[[document-conventions]]
=== Document Conventions

This manual also uses the following typographic conventions.

[width="100%",cols="25%,75%",options="header",]
|=======================================================================
|*Convention* |*Description*
|*Bold* |Indicates text on a Web page, other than the page title, including
menus, menu options, buttons, fields, and labels.
|_Italic_ or < > angled brackets |Indicates a variable, which is a placeholder
for actual text provided by the user or system. Angled brackets (< >) are
also used to indicate variables.
|`screen/code` |Indicates text that is displayed on screen or entered by the user.
|[ ] square brackets |Indicates optional values.
|{ } braces |Indicates required or expected values.
| \| vertical bar | Indicates that you have a choice between two or more
options or arguments.
|=======================================================================


[[the-symetryml-difference]]
== The SymetryML Difference

SymetryML is an application that allows organizations to leverage their
existing data to gain further insight into their current business
processes. Whether you want to increase user clicks, select the most
appropriate product, or analyze the relationship between various factors
affecting your business, SymetryML can offer you a real-time, scalable,
and easy-to-deploy platform on which to build the next generation of
data-driven applications within your organization.

A unique feature of SymetryML is the adoption of the *online learning*
approach to predictive analytics. This is accomplished by separating the
learning phase from model creation. By avoiding the complete data scan
typically required by the majority of other systems, users are able to
experiment with many different models, using a varying selection of
attributes, and find the perfect combination of attributes for their
particular task. Separating learning and modeling also allows SymetryML
to account for new attributes dynamically, including increments and
decrements. Adding new attributes is simply a matter of feeding new data
into SymetryML. If at some stage the data is found to be erroneous,
removing these records from SymetryML becomes a simple operation.
Experimenting with large datasets becomes a much more fluid and less
time-consuming process, thus enabling faster deployments and a quicker
time-to-market.

[[the-data-mining-lifecycle]]
== The Data-Mining Lifecycle

[[overview]]
=== Overview

Data mining is about explaining the past and predicting the future using
data analysis. While the term is relatively new, the process of using
empirical data to gain further insight has been around long enough to
produce a well-defined methodology that guides the development of such
projects.

[[problem-definition]]
=== Problem Definition

Defining a data-mining problem requires a complete understanding of a
project’s objectives and requirements from a domain perspective, and
then converting that knowledge into a data-mining problem definition
with a preliminary plan designed to achieve the objectives. Data-mining
projects are often structured around the specific needs of an industry
sector or even tailored and built for a single organization.

A successful data-mining project starts from a well-defined question or
need. For example, a business might want to increase the click-through
rate (CTR) for its upcoming email campaign, or an insurance company
might want to classify customers into different risk categories. These
examples are precise enough to be formulated as a data-mining model with
a well-defined objective.

The next step is to gather historical data and adjust it to fit our
problem.

[[data-preparation]]
=== Data Preparation

Data preparation involves constructing a dataset from one or more data
sources to be used for exploration and modeling. Best practice requires
starting with an initial sample dataset to get familiar with the data,
to discover first insights into the data, and to have a good
understanding of any possible data quality issues.

Data preparation is often a time-consuming process and heavily prone to
errors. The old saying "garbage in, garbage out" is particularly
applicable to those data-mining projects in which data gathered may
contain invalid, out-of-range, or missing values. Analyzing data that
has not been carefully screened for such problems can produce highly
misleading results.

[[data-exploration]]
=== Data Exploration

Data exploration is the process of describing data using statistical and
visualization techniques. The data is explored in order to bring
important aspects of it into focus for further analysis.

SymetryML provides functionality for both _univariate_ analysis and
_multivariate_ analysis. Univariate analysis focuses on one attribute at
a time and is an easy way to verify that the data has been imported
correctly and is in line with the previous assumptions made by the
analyst. Multivariate analysis, on the other hand, allows for the study
of many attributes and the relationships between them. For example:

* Are certain attributes correlated?
* Do values of one attribute show statistical dependence on the values
of another?

These questions can generally be answered with the help of multivariate
analysis and will guide the attribute choice for the final model.

[[modeling]]
=== Modeling

Predictive modeling uses historical data to predict the probability of
an unknown event. If the unknown outcome is categorical in nature (for
example, click vs. non-click on a banner ad), you are solving a
_classification_ problem and will need to build a classification model.
In other words, you are trying to classify a particular case into the
most appropriate group.

A _regression_ model, on the other hand, attempts to predict the value
of a continuous variable. An example of this could be the average value
of a shopping cart on your site or average house price in a particular
area. In both cases, you use a set of input attributes (that is,
features and predictors) to model a particular dependent, target,
variable.

_Sequence_ models attempt to describe the behaviour of sequence of events and model
data that is temporal in nature. What is the next most likely state? How likely that a particular
sequence would occur based on our model? These are the typical questions that sequence models attempt
to answer.

_Anomaly_ models are unsupervised learners, they do not require the target attribute to be present. Instead,
they assess the similarity of a particular record to a set of records on which the models was trained on.
They excel in situations where the number of labeled cases is very small, or cases where
the true label for the record is unknown. Instances which are drastically different from the
ones the model was build with, will yield a higher anomaly score than those which are aligned with what
the model has seen before.

[[evaluating-models]]
=== Evaluating Models

Model evaluation is an integral part of the model-development process.
It aids in finding the best model that represents the process and in
presenting how well the chosen model will work in predicting future
outcomes.

A common approach to performing model evaluation is to separate the
historical data into two parts.

* The first part, often the larger of the two, will serve as the
training set. This part will be used to build the model.
* The remaining part, typically referred to as the test set, will be
left out until the model-building process is complete.

After the model is ready, its performance can be evaluated with this
test set. The outcomes for the test set are known in advance. Evaluating
the model simply involves keeping a tally of the number of times it
predicts the outcomes of the test set correctly.

[[deployment]]
=== Deployment

The concept of deployment in predictive data mining refers to the
application of a model for prediction of new data. Building a model is
generally not the end of the project. Even if the purpose of the model
is to increase knowledge of the data, the knowledge gained will need to
be organized and presented in a way that can be used.

Depending on the requirements, the deployment phase can be as simple as
generating a report or as complex as implementing a repeatable
data-mining process. In many cases, it will be developers, not data
analysts, who perform the deployment steps. However, even if analysts
perform the deployment effort, the developers must understand up front
what actions will be needed to use the created models. 

[[symetryml-key-concepts]]
== SymetryML Key Concepts

[[working-with-symetryml]]
=== Working with SymetryML

SymetryML offers users two ways to access its core functionality:

* SymetryML Web
* SymetryML REST

SymetryML Web offers a complete GUI for accessing the most common
functionality. It allows you to add data, learn, and build predictive
models on that data. Most functions available in SymetryML Web can be
replicated via individual service calls to SymetryML REST.

For a detailed description of SymetryML REST and how it can help you
simplify deployment, refer to the __SymetryML API Reference Guide__.

[[authentication]]
=== Authentication

To access SymetryML Web functionality, you log in with a predefined set
of credentials. The process of generating these credentials is described
in __SymetryML Admin User Guide__.

[[symetryml-web-ui]]
=== SymetryML Web UI

After you log in to SymetryML Web, the SymetryML Web interface in <<id-sml-ui-panels>> appears. This interface allows you to fully leverage SymetryML
functions.

The interface is organized into three components:

* Main accordion
* Contextual panel
* User admin panel

Within these panels, you can interact with various SymetryML objects,
such as models, data sources, and encoders.

[[id-sml-ui-panels]]
image::media/web/sml_ui_panels.png[title='Symetry Web Main UI Components', width=100%, align="center"]
{nbsp} +

.UI Panels
[width="100%",cols="17%,83%",options="header",]
|=======================================================================
|*UI Component* |*Description*
|User Admin |Shows the active user and the current version of the SymetryML
application. This panel also notifies you about version updates.
|Main Accordion |Provides a quick overview of data sources, encoders and current
projects.
|Contextual |Details about specific SymetryML objects can be viewed in a
contextual panel. For instance, double-clicking a learned project object shows
summary statistics, and allows you to perform hypothesis testing and analysis
of variance (ANOVA) exploration.
|Job Status |Provides information about the status of currently running jobs.
|=======================================================================

.UI Windows
[width="100%",cols="20%,80%",options="header",]
|=======================================================================
|*Panel* |*Description*
|Projects |Provides access to the heart of SymetryML: the Symetry project.
Here you can learn and explore new data, build and evaluate your models,
and make predictions.
|Data Sources |Expand to show a general overview of the data sources currently
registered with SymetryML. This allows you to validate and delete various data
sources used within your project.
|Encoders |Allows you to access additional information for the encoders you
might have created.
|Status |Lists jobs running on your SymetryML server.
|=======================================================================

image::media/web/sml_univariate.png[title='Contextual Panel', width=100%]
{nbsp} +

image::media/web/sml_user_info.png[title='User and Version Information', width=25%]

[[data-source]]
=== Data Sources

The first step when working with SymetryML is to define a data source.
Data-source objects are typically flat text files stored at a remote
location. The remote location can be any of the following : SFTP, Local, Amazon
S3, HTTP/HTTPS, JDBC, Redshift, and Spark S3.

The desired target attribute must be either binary or continuous.
Categorical target attributes should have their values recoded into
corresponding binary indicators.

After registering a particular data source with SymetryML, you have
everything you need to learn from the newly added data.

For more details on how create data source please refer to the
<<working-with-data-sources>> section.

[[streams]]
=== Streams

Streams are a dynamic and constantly changing source of data. Unlike their flat file
counterparts, streams do not have an end. As of now, SymetryML only supports Kafka Streams.
More information about Kafka streams can be found https://kafka.apache.org/[here]. Please also consult
the <<working-with-streams>> section of this document.

Once associated with a particular project, streams enable the project to learn new data as
it becomes available  in a continuous  fashion without user interaction.

[[symetry-job]]
=== Symetry Job

Most interactions with SymetryML involve launching a background process
on the Symetry server. To view the currently running jobs and their
progress, click the *Job Listing* button.

Processor-intensive jobs often prevent other jobs from starting. This is
normal and helps ensure the running stability of the SymetryML server.

image::media/web/job_status_current.png[title='Job Status', width=50%]

[[encoder]]
=== Encoder

In data mining, the process of transforming a categorical attribute into
a continuous attribute is called _encoding._ Within SymetryML, an
encoder object allows you to transform high-cardinality attributes into
meaningful data points that are more predictive than their original
form. Because certain modeling algorithms have strict requirements for
the type of inputs they accept, an encoded attribute is more flexible in
nature than its categorical counterpart.

The current version of SymetrML supports two types of Encoders:

* Probabilistic Encoding - A method which replaces a categorical value _x_ with a
probability value of positive target value given _x_, or `P(target=1 | X=x)`

* Feature Hashing - an implementation of the https://en.wikipedia.org/wiki/Feature_hashing[hashing trick] approach to encoding *String* values

[[project]]
=== Project

Within SymetryML, a project is a top-level container for a collection of
data files, models, prediction results, and assessment results. While no
particular convention is enforced, we recommend that the project contain
elements closely related to a particular data-mining initiative. In
practice, this means that each project should focus on a related set of
data.

The following sections provide a brief description of the types of projects SymetryML provides.

[[cpu]]
==== CPU

Computation is performed on the CPU. Most common choice for small to
medium sized data sets.

[[sequence]]
==== Sequence

Computation is performed on the CPU. Used for sequence data sets.

[[gpu]]
==== GPU

Available if the environment is GPU enabled. Computation is performed on
the GPU. Provides improved performance over CPU based projects with very wide datasets (i.e.large amount of features)

When creating a New Project, the first window will require a choice of Project Type. If you only have access to 1 GPU, simply select the `GPU` option, and select `Next`. If you have access to, and wish to utilize, more than 1 `GPU`, then select the `Multi-GPU` option, and then fill out the `Num. GPU*` that you will be utilizing:

image::media/web/webUI_selectMultiGPU.png[title='Select Multi-GPU', width=50.0%]

[[mgpu]]
==== Multi-GPU

Available if the environment is GPU enabled. Reserved for the widest possible datasets.
Multi-GPU projects cannot be persisted. SymetryML allows the Multi-GPU project to be of backed by either
*float* or *double*. Use of doubles is recommended as they offer higher levels of precision. However,
the extra precision does come with a greater memory footprint.

image::media/web/webUI_selectNumberOfGPU.png[title='Select Number of GPU', width=50.0%]

[[partition]]
==== Partition

Allows for a more specialized approach to learning your data. This is
done by partitioning the internal representation on the categorical column
of your choice. For multiclass classification problems, a partitioned project
will generally produce more accurate representation. However, the improved
performance does come at the price of additional memory overhead.
As a rule of thumb, partitioned project will take up *N* times
more memory as their CPU/GPU counterparts, where *N* is the cardinality
of the partition column.

[[power-transformation]]
==== Power Transformation

Linear regression assumes that the target attribute is normally distributed. While in real world scenarios
this is often not the case, we can still improve the performance of the regression model by transforming the target
into something resembling a normal distribution. The method of transforming that is used within SymetryML is the Yeo-Johnson transformation.

SymetryML projects with power transformation enabled will automatically create new attributes representing various power transformations of
the target so that they can be modelled against the existing features. These additional target features will have a
prefix and separator to easily pinpoint them. (e.g `pt_sepal_width^-2.0`, `pt_sepal_width^-1.8`, `pt_sepal_width^-1.6`, ..., `pt_sepal_width^1.8`, `pt_sepal_width^2.0`).
It's possible to configure the prefix and separator - `pt_` and `^` in our previous example.
Please refer to the <<../rest/SML_REST_API_Reference_Guide.adoc#power-transf-sym-ctrl-parameter,power ctrl parameter>> table for details.

Once a project has learned these transformations, a Power Regression model can be build which would select the optimal transformed target.

[[online-models]]
==== Online Models

While the majority of the models in SymetryML can be build after the project has learned, Kaplan-Meier(KM) and Random Forest(RF)
must be specified before any data has been processed. This allows SymetryML to process the data and fit the models in one pass.
For details on how to correctly specify RF and KM parameters, please see the description of advanced project properties:
<<rf-projects>> and <<km-projects>>

[[km-models]]
===== Kaplan-Meier

Kaplan Meier(KM) is a survival model which can estimate a survival function from lifetime data. With the aid of the survival function,
it is possible to estimate the probability of an adverse event not occurring after a specific point in time. The most common usage of
such models occurs in the field of clinical trials where a researcher might be interested in the probability that a patient will survive
beyond some time __t__.

To build the KM model, your data must be contain the following types of columns:

* Time column - integer valued column representing discrete time.
* Event column - binary column coded in a way where 1 represents an event occurring and 0 represents the subject leaving the study.
* Group column - An column which will partition the model and compute a separate survival function for each member of the group

[[rf-models]]
===== Random Forest

Random Forest is an ensemble algorithm which builds and aggregates the output of multiple decision trees into a single prediction.
Current version SymetryML supports classification models in binary and multiclass forms as well as regression and anomaly models.
As with other Online Models, RF parameters must be specified at the beginning of the project creation process.
See section <<rf-projects>> for additional details and the specifics of the parameters required.

==== Histogram

Histograms can be enabled for a project at anytime via the REST API. However, in WEB UI they can only be enabled
at the beginning of the project creation process. In addition to providing visual information on the attribute inside the project,
histograms allow a project to create HBA Models. While the information provided by the histograms
can often times be invaluable, they do reduce the speed of project updates. Hence, they should be used sparingly in production environments
that require fast learning.

[[fusion]]
==== Fusion

A Fusion project combines the information from multiple source projects in a single place.
In the parlance of SymetryML, these component projects will be referred to as fusion cells
and the project that aggregates them is the fusion project.
The use case which benefits the most from the use of a fusion project is one which contains
large amounts of streaming data. In such a scenario having a single node process all of the incoming
data becomes infeasible. Instead, the stream would be split amongst several component project nodes(cells) which will
handle their share of the data independently. A fusion project would then query these cells and combine their
data within itself. The merging occurs behind the scenes and does not require any action from the user.
The end result is a fusion project that behaves as if it has processed all of the data by itself. The user is then
able to explore the data, build models, make predictions and etc. just like any other project.


.Suggested Project Type
[cols=",",options="header",]
|====================================
|*Use Case* |*Suggested Project Type*
|Sequence/Temporal |Sequence
|1 to 250 Attributes |CPU/Partition
|250 to 10,000 Attributes |GPU
|10,000+ |Multi-GPU
|Streaming |Fusion
|====================================

[[exploration]]
=== Exploration

After data is added and learned, use SymetryML Web’s explore feature to
verify that your project has been processed correctly. In other words, a
project becomes _explorable_ after a data source has been added to it
and learned. Using univariate and bivariate analyses, you can determine
the likely selection of candidate pairs that will provide insight for
model building. Within SymetryML Web, tools for exploratory analysis are
accessed via tabs in the contextual panel.

*Auto Refresh* functionality will ensure that your web client will
always be synced with the state of the project on the SymetryML Server.
This feature can be disabled to improve performance for projects with
large number of attributes.

The *Univariate* panel shows the basic statistics for attributes
from a particular data source. View this information as a quick sanity
check to validate whether SymetryML interpreted the data correctly.

image::media/web/sml_univariate.png[title='Univariate Panel', width=100%]
{nbsp} +

The *Correlation* panel allows you to perform bivariate analyses
on the learned data. This enables you to learn quickly about the degree
of associativity between your variables and helps when creating
subsequent models. In general, avoid models with highly correlated input
variables. For example, if variable A is highly correlated with variable
B, choose only one for the final model.

image::media/web/sml_correlation.png[title='Correlation Panel – Graph', width=100%]
{nbsp} +

*Hypothesis testing* provides a formal way to determine the
effect of various inputs on your continuous target. Using this testing,
you can determine whether the difference in the continuous variable is
related to the values of the binary variables, or test the difference between
groups of continuous variables.

image::media/web/sml_hypothesis_testing.png[title='Hypothesis Testing', width=100%]
{nbsp} +

Like a correlation analysis, hypothesis testing is a way to perform a
bivariate analysis and assess how variables interact. It is best used to
determine if the difference in mean/variance between two groups is statistically
significant. For cases where you need to look at the difference between more
than two groups, please refer to our section on ANOVA.

Each test can be specified in the following fashion:

* the average/variance of a numerical attribute with a known average/variance
* average/variance of two numerical attributes against each other
* two conditional averages of a numerical attribute given one binary attribute
* two conditional averages of a numerical attribute given two binary attributes


The *Z Test* assesses whether the difference between the averages of two
groups is statistically significant.

The *T Test*, like the Z Test, assesses whether the averages of two
groups are statistically different from each other when
the number of data points is less than 30.

The *F Test* compares the variances of two groups.

*Analysis of variance (ANOVA)* assesses whether the averages of
more than two groups are statistically different from each other, under
the assumption that the corresponding populations are normally
distributed. Use ANOVA to compare the averages of two or more numerical
attributes, or two or more conditional averages of a numerical
attribute, given two or more binary attributes (two or more categories
of the same categorical attribute).

image::media/web/sml_anova.png[title='ANOVA', width=100%]
{nbsp} +

The *Chi-square Test* determines the association between two or
more categories. This test compares the difference between the expected
contingency table and the observed one to determine the strength of the
association between the two categories of interest. The output of a
chi-squared test is a probability value that corresponds to the level of
association. A p-value that is very close to zero corresponds to a
strong dependency between the two categories, while a higher p-value
implies a certain degree of independence.

image::media/web/sml_chi_squared.png[title='Chi-square Test', width=100%]
{nbsp} +

The *Principal Component Analysis (PCA)* identifies the most
important components of a given dataset and maps the raw observations
onto this new vector space. Variable importance can be inferred by
looking at the Eigen vectors generated by this transformation.

Within SymetryML**,** use PCA shortly after the project completes
learning:

1.  Click the *PCA* tab.
2.  Select the attributes of interest.
3.  Click the *PCA* button.

image::media/web/sml_pca.png[title='PCA', width=100%]
{nbsp} +

With the help of the *SVD* panel, you are able to
perform _Singular Value Decomposition_. This allows you to select potential attributes of interest when
you actually want to build a model.

image::media/web/sml_svd.png[title='SVD', width=100%]
{nbsp} +


*Information Gain* is a metric that measures the change in information
entropy for a specific attribute. In the context of SymetryML, use
information gain to find attributes that will provide the best
separation for your particular target of interest. Variables with high
information gain relative to your target will generally be better
predictors than their counterparts with low gain. For example, the following figure (<<id-sml-information-gain>>) shows
that values of attributes characterizing _petal width_ play the most important factor in
identifying the _Iris Setosa_ species of the Iris plant.

[[id-sml-information-gain]]
image::media/web/sml_information_gain.png[title='Information Gain', width=100%]


*Variance Inflation Factor* (VIF) allows the user to measure the degree of collinearity between a set of factors.
Within SymetryML, VIF can be used to select a set of candidate features for one's model.
Attribute with a VIF value of 5 or greater is likely to have a high degree of collinearity with one of its peers.
Consider removing such attribute from your candidate set.

[[id-sml-vif]]
image::media/web/sml_vif.png[title='Variance Inflation Factor', width=100%]

[[models]]
=== Models

Unlike most data-mining toolkits, SymetryML separates the tasks of
learning and model building into two discrete steps. The classical
approach assumes these two steps are synonymous by defining model
building within the actual learning phase. SymetryML achieves this
separation by scanning the input data in such a way as to defer model
creation to a later stage. This allows SymetryML to reduce the memory
footprint required to learn large data sets and allows models to be
created instantaneously. After the data has been learned, SymetryML can
generate classification and regression models.

[[using-classification-models]]
==== Using Classification Models

_Classification_ refers to the data-mining task of trying to build a
predictive model when the target is categorical. The main goal of
classification is to organize a dataset into mutually-exclusive groups,
so that the members of each group are as close to one another as
possible, and different groups are as far from one another as possible.

Types of classification models include:

* LDA - linear discriminant analysis.
* LSVM - linear support vector machine.
* Bayes - Naïve Bayes.

If the project is partitioned (i.e., split on a particular column), two
additional model types become available:

* MetaLDA
* MetaQDA

These models handle the multi class classification problem much better
than their regular counterparts.


For projects that are enabled for Random Forest, see <<rf-projects>>, you will gain access
to a power powerful set of models which gracefully handle regression, classification and anomaly problems.

* Random Forest (classification)
* Random Forest (regression)
* Random Forest (anomaly)

[[using-regression-models]]
==== Using Regression Models

_Regression_ refers to the data-mining problem of attempting to build a
predictive model when the target is numerical. The simplest form of
regression, simple linear regression, fits a line to a set of data.

Types of regression models include:

* MLR - Multi-linear regression.
* LSVR - Linear support vector regression.
* Power Regression - Power regression model
* Lasso - Lasso regression
* Ridge - Ridge regression
* Elastic Net - Linear combination of Lasso and Ridge regularization

The last three models models are related, with Lasso and Ridge being special cases of the Elastic Net model.
Working with Elastic Net models allows the user to specify regularization parameter which help prevent overfitting the training data.
The primary parameters, Eta and Lambda, can either be specified directly, or chosen with the help of AICc search algorithm.

.Required Elastic Net Parameters
[width="100%", cols="<25%,<25%,<50%",options="header",]
|=============================
|Parameter |Type |Description
|*Lambda* | Number |  Lambda parameter of Elastic Net
|*Eta* | Number |  Eta parameter of Elastic Net
|=============================

Optional parameters for Elastic Net are the following:

.Optional Elastic Net Parameters
[width="100%", cols="<25%,<25%,<50%",options="header",]
|=============================
|Parameter |Type |Description
|*Maximum # of Iterations* | Number |  Maximum number of iteration
|*Standardize* | Boolean |  Transform each feature to the same scale (Z-score normalization)
|*Center Target* | Boolean |  Center target around zero
|*Debias* | Boolean |  Debias the estimator
|=============================


Akaike information criterion (AIC) is a model selection heuristic which allows the
user to select the optimal __Eta__ and __Lambda__ hyperparameters for their Elastic Net models using in-sample data. The AIC implementation in SymetryML
is corrected for small sample sizes. This adjustment is commonly referred to as AICc. More detailed description of the AIC
and small sample correction can be found https://en.wikipedia.org/wiki/Akaike_information_criterion#AICc[here].
In the context of SymetryML, the use of AIC can be selected by specifying the following options.

.AIC Hyperparameters
[width="100%", cols="<30%,70%",options="header",]
|===================
|HyperParameter | Description
| *AICc*              | Boolean, true to enable AIC. Default is false.
| *Lambda Min Power*  | Minimum value of Lambda. Specified as 10 ^ *min_lambda_power*. Default is -10.
| *Lambda Max Power*  | Maximum value of Lambda. Specified as 10 ^ *max_lambda_power*. Default is 3
| *Lambda Steps*      | Number of possible Lambdas between *min_lambda_power* and *max_lambda_power*. Default is 100
| *Eta Min*           | Minimum eta. Default is 0.
| *Eta Max*           | Maximum eta. Default is 1.
| *Eta Steps*         | Number of possible Etas between *min_eta* and *max_eta*. Default is 11.
|===================

image::media/web/aic.png[title='Elastic Net parameters', width=50%]
{nbsp} +

[[using-sequence-models]]
==== Using Sequence Models

A *Markov Chain* (MC) is a graphical representation of a sequence of
states and the relationship among them. At its most basic, a MC model
will tell us the probability of transitioning to one state from another.

Like the MC a *Hidden Markov Model* (HMM) is a graphical model
describing the probabilities of transitioning from one state to another.
It extends the Markov process by focusing on two states: observed and
hidden. The observed states, as their names imply, are the states that
are visible at any given time. While hidden states are not visible
directly, the user knows of their existence. The most common use case
for HMM is to infer the sequence of underlying hidden states given a set
of visible states.

[[using-lifetime-models]]
==== Using Survival Models

Survival Models, such as *Kaplan-Meier*, estimate a survival function which give
a probability that a subject will survive beyond a certain point in time(i.e, the adverse event not occurring). The subject could
be a patient in a clinical study, a device in failure analysis, or any other object which has a time dependent lifespan.

image::media/web/km.png[title='KM Survival Function', width=50%]
{nbsp}

[[using-anomaly-models]]
==== Using Anomaly Models

Within SymetryML, anomaly models allow the user to gauge how different a particular record is from the ones
a model has seen before. A record that differs slightly from those on which an anomaly model was built on, will have a lower
anomaly score. Unlike their classification and regression counterparts, anomaly models do not require a target attribute to be specified.

The anomaly models available in Symetry are:

* Random Forest  - RFA (requires a RF enabled project)
* Out of Sample PCA - OOSPCA
* Histogram Based Anomaly - HBA (requires a histogram enabled project)

[[reducing-models]]
==== Reducing Models

SymetryML can reduce models automatically to find one with the best
subset of attributes. This is useful when working with datasets that
have many attributes. SymetryML uses a heuristic to build various
models, compares the models, and keeps the best one. This comparison is
performed efficiently by using the intrinsic values of the models.

Not all modeling algorithms are suited for this type of intrinsic-value
comparison. These techniques work only when building LDA and MLR
algorithms.

[[selecting-models]]
==== Selecting Models

For models which don't support reduction, feature selection can be performed by
specifying an out of sample dataset against which various feature combinations
can be tested. This approach works by building multiple models and testing their performance
against the out of sample data. The best regression model is one that has the lowest RMSE.
For classification the model with the highest AUC will be chosen.

In addition to supplying the out of sample dataset, the user has to choose one of the following search heuristics.

[[auto-select-heuristic]]
[width="100%",cols="<30%,<70%",options="header",]
|================================================================
| Name  | Description
| Forward Backward | A heuristic that does the following: +
1. Iteratively add as many features as possible while keeping the best model +
2. Iteratively remove as many feature as possible while keeping the best model +
3. repeat a specific number of times. +
| Brute Force | Brute force will try all possible combinations of the input attributes. It should not be used if you have more than 17-18 attributes.
| Max Number of Iterations | Randomly create a model by trying a specific number of random number of permutations of the features.
| Max. Number of Seconds | Randomly create a model by trying a random number of permutations of the features for a maximum number of seconds.
| Simple | The simple heuristic starts with one feature and then incrementally adds one additional feature until it tries all the features. It then keeps track of the best model.
|================================================================

Once the search heuristic has been chosen, the user can specify the size of the *Search Space*.

* Tiny
* Small
* Normal
* Large

Larger search spaces will typically test a greater number of
hyperparameter values but will take much longer to run.

[[generating-new-predictions]]
=== Generating New Predictions

After the models are created, they can generate new predictions. Like
many SymetryML functions, predictions can be performed through a RESTful
API provided by SymetryML REST service or with the SymetryML Web
application.

Version 5.2 of SymetryML also features the option of enabling a Dynamic Imputer when making predictions.

Dynamic Imputer is needed because real world data often times contains missing values. While these missing values are
handled gracefully by some machine learning algorithms, others require all values to be present
in order to generate a prediction. For the latter case, SymetrML can impute the missing values in one of the following ways:

* Replace the missing value by the average of its column. This is the default behaviour.
* Impute the missing attribute by building a separate model which will attempt to predict the missing attribute based on the
the attributes that are available.

The second option is what we refer to as the Dynamic Imputer. The online nature of SymetryML enables these imputation models to be
build on the fly as the prediction file is being processed. Enabling this functionality is as simple as checking the *Impute Missing Values*
option when making a prediction or generating an assessment.

image::media/web/impute.png[title='Dynamic Imputer Option', width=50%]
{nbsp} +



[[assessing-the-accuracy-of-a-model]]
=== Assessing the Accuracy of a Model

After you create your project, data has been added and learned, and the
model has been built, you can test the accuracy of the model by entering
historical data that was not used during the learning. You can then
proceed to “hide” the correct value of the target attribute from the
model and have the model predict the outcome. By comparing the answer
provided by the model with the actual result, and counting the number of
times the model made the correct guess, you can assess the accuracy of
the model. Using SymetryML Web, you can perform this type of assessment
easily for most models.

For classification models with binary targets, feeding labeled data into
SymetryML generates a confusion matrix and gain chart that can be used to assess
the performance of the models. Assessment of multi-target (for example, QDA)
models yields a multi-class confusion matrix.

Assessing a regression model yields a distribution of errors along with
standard regression metrics such as Root Mean Squared Error (RMSE) and
Mean Absolute Error (MAE). For more information, see section <<assessing-model-performance>>.

[[using-symetry-web]]
== Using Symetry Web


[[authentication-1]]
=== Authentication

Authentication with the SymetryML application is achieved using a
predefined user ID and security key. The randomly generated
security key was given to you when you initially registered for the
application.

[[id-login-screen]]
image::media/web/login_screen.png[title='Login Screen', width=50%]
{nbsp} +

If this is your first time registering, use the user ID *admin* and user
secret key **admin**. Click **Sign In**. The system redirects you to the
registration section of Symetry Web that will guide you through the
registration process.

[[working-with-data-sources]]
=== Working with Data Sources

[[creating-new-data-sources]]
==== Creating New Data Sources

To create a new data source:

1. Open the *Data Sources* accordion and click the *Add Data* button. A New Data
Source wizard appears.
2. Select the preferred **Data Source Type**. The wizard forms change, depending
on the type selected, as shown in the following figures.
+
image::media/web/s3_ds.png[title='Amazon S3 Data Source', width=50%]
{nbsp} +
+
image::media/web/sftp_ds.png[title='SFTP Data Source', width=50%]
{nbsp} +
+
image::media/web/local_ds.png[title='Local Data Source', width=50%]
{nbsp} +
+
image::media/web/redshift_ds.png[title='Redshift Data Source', width=50%]
{nbsp} +
+
image::media/web/jdbc_ds.png[title='JDBC Data Source', width=50%]
{nbsp} +
+
image::media/web/spark_ds.png[title='Spark Data Source', width=50%]
{nbsp} +
+
image::media/web/http_ds.png[title='HTTP Data Source', width=50%]
{nbsp} +

3. Ensure your data source settings are valid.
4. Click *Finish* to add the data source.
+
image::media/web/verify_new_data_source.png[title='Verify New Data Source', width=50%]


[[uploading-data-source]]
==== Uploading Data Source

Files local to the client’s machine can be uploaded onto a SFTP
server via the Upload Wizard. This can be done by selecting a
destination source and selecting a local file from the user’s computer.

image::media/web/upload_file.png[title='Upload File', width=50%]

[[viewing-data-sources]]
==== Viewing Data Sources

To view your newly created data source:

1.  Double-click the data source node under the *Data Sources*
accordion.
2.  Inspect your newly added data.

[[id-data-preview]]
image::media/web/data_source_preview.png[title='Data Source Preview', width=100%]

[[deleting-data-sources]]
==== Deleting Data Sources

To delete a data source:

1.  Right-click the *Data Source* node, and then click *Delete*.
+
image::media/web/data_source_delete.png[title='Data Source Deletion', width=25%]

[[editing-data-sources]]
==== Editing Data Sources

To edit a data source:

1.  Right-click the *Data Source* node, and then click *Edit*.
2.  Update the fields as appropriate, and then click *Next* to continue.
3.  After validating your data source, click *Finish* to commit the changes.
+
image::media/web/data_source_editing.png[title='Data Source Editing', width=25%]
{nbsp} +

[[working-with-streams]]
=== Working with Streams

Unlike other Data Sources, streams cannot be created independent of a project.
The option to add a stream only exists when you:

* Have an existing SymetryML project
* Create a new SymetryML project from scratch

In both cases, creating a stream would require you to specify at minimum
the following information:

* *Bootstrap Servers*
* *Schema Registry*
* *Kafka Topic*

image::media/web/add_stream.png[title='Stream Info', width=50%]
{nbsp} +

*Time btw. Persists* is an optional parameter that controls the frequency at which
SymetryML persists a project with a stream. Default value of 300 seconds, should be sufficient
unless your schema contains a large number of attributes (1000+).

*Start from Beginning* checkbox would read the earliest possible data from the stream.
Unselecting this option would only update the project with the data that will be generated
from this point in time.

Advanced Kafka parameters could be enabled specified by clicking the *Kafka Options* button
and adding the corresponding parameter/value pair.

[[creating-project-add-stream]]
==== Adding a Stream to an existing Project

1. Right-click the project node, and then click *Add Stream*.
2. Specify the required stream info (bootstrap servers, topic, and etc.)
3. Ensure your information is valid and click *Next*
4. Verify the stream in the preview panel. Click *Next* to continue.
5. In the final panel specify the correct type mapping and click *Finish*

[[creating-new-project-stream]]
==== Creating a Project with Stream

When creating a new project, adding a stream can be performed by simply:

1. Selecting *New Data Source* on the data selection panel
2. Specifying the required stream info (bootstrap servers, topic, and etc.)

See <<creating-new-projects>> for more information.

==== Stoping and Restarting a Stream

Once added to a project, a stream will be continuously polled and will cause the
project to be updated automatically with new incoming data. This behaviour  can be
paused and restarted again.

image::media/web/stream_options.png[title='Stream Info', width=25%]
{nbsp} +

To stop the update behaviour:

1. Right-click on the stream node
2. Click *Stop Stream*


While this does stop the project from being updated, it has no effect on the underlying stream.
The Kafka Stream will continue to ingest  new data in the background.

Resuming project update behaviour can be done in one of two ways:

* A stream can be resumed from the point where it was paused (*Resume Stream*)
* It can be restarted from the very beginning. (*Start from Beginning*)

The correct restart point will depend on the architecture of your Kafka cluster.
If the cluster allows for storage of large volume of data, simply resuming might
be the best option. On the other hand, if the data in the cluster is changing
rapidly, restarting from the beginning might be more optimal.

==== Stream Metrics

Information about a Kafka Stream can be obtained by right clicking on the stream node
and selecting *Stream Metrics*

image::media/web/stream_metrics.png[title='Stream Metrics', width=50%]

==== Stream Errors

*Error Log* allows the user to diagnose any potential problems that might occur
when interfacing with a Kafka Stream. This is the first place you should look when
troubleshooting.

image::media/web/stream_errors.png[title='Stream Error Log', width=50%]

[[working-with-encoders]]
=== Working with Encoders

[[creating-new-encoders]]
==== Creating New Encoders

To create a new encoder:

1.  Expand the *Encoders* accordion, and then click the *New Encoder*
button. A *New Encoder* wizard appears .
+
image::media/web/new_encoder_wizard.png[title='New Encoder Wizard', width=50%]

2.  Assign a new name to your encoder, and then click *Next* to
continue.
3.  Select an appropriate data source, and then click *Next* to
continue.
4.  Ensure that your data is valid, and then click *Next* to
continue.
+
[[id-encoder-ds-valid]]
image::media/web/encoder_data_preview.png[title='Encoder Data Preview', width=50%]

5.  Select the appropriate target variable.
6.  Click *Finish* to build the encoder.
+
[[id-encoder-target]]
image::media/web/encoder_target_mapping.png[title='Encoder Target Mapping', width=50%]

[[viewing-encoder-metadata]]
==== Viewing Encoder Metadata

To view the metadata for an encoder:

1.  Double-click the encoder node.
+
[[id-encoder-tree]]
image::media/web/encoder_tree.png[title='Encoder Tree', width=25%]

[[editing-encoders]]
==== Editing Encoders

After you create the encoder, you can modify its internal state to
satisfy your needs.

1.  Under the encoder metadata view, double-click the desired encoder
**Key**. The key editor appears.
2.  Use the key editor to modify the *Total Count* and *Sum* values
+
[[id-encoder-editor]]
image::media/web/encoder_key_editor.png[title='Key Editor', width=100%]

[[deleting-encoders]]
==== Deleting Encoders

To remove an encoder from your project:

1.  Right-click the encoder node, and then click *Delete*.
+
image::media/web/sml_encoder_delete.png[title='Deleting an Encoder', width=25%]
{nbsp} +

[[adding-data-sources-to-encoders]]
==== Adding Data Sources to Encoders

To add data sources to an encoder:

1.  Right-click the encoder node, and then click *Add Data*.
+
image::media/web/sml_encoder_add_data.png[title='Adding a Data Source to an Encoder', width=25%]

[[working-with-projects]]
=== Working with Projects

[[creating-new-projects]]
==== Creating New Projects

Project creation is one of the first steps in performing data analysis
within SymetryML. As a user you also have the option of deciding whether
the project should be persisted. Disabling persistence will improve the
responsiveness of the application but your data will not survive a
system reboot. To create a new project:

1.  Expand the *Projects* panel, and then click the *Create Project*
button.
2.  Select the appropriate project type.
3.  Assign a new name to your project, optionally assign an
encoder to your project or select the order of the sequence. Click
*Next* to continue.
+
image::media/web/new_project_start.png[title='New Project', width=50%]
{nbsp} +

4.  Select an existing data source or define a new data
source directly from the project wizard.
+
image::media/web/new_project_ds_selection.png[title='New Project Data Selection', width=50%]
{nbsp} +

5.  Ensure that your data is valid.
+
image::media/web/new_project_data_preview.png[title='New Project Data Preview', width=50%]
{nbsp} +

6.  Click **Next**. The type-mapping panel appears.
7.  On the type-mapping panel, verify the data types for the attributes
inside the file. You can change the data types to ones that are more
appropriate. Click *Finish* to start the project-creation task.
+
image::media/web/project_type_selection.png[title='Type Selection', width=50%]
{nbsp} +

8.  After the project creation completes, the change is shown in the
project tree.
+
image::media/web/project_tree2.png[title='Project Tree', width=25%]
{nbsp} +

For more specialized project types, a user has the option of clicking on the dropdown option
of the *Create Project* button. This allows one to build one of the following project types:

* *Empty Project* - Project with no data. Data can be added in a separate step.
* *Local Project* - Project local to the SymetryML instance. Same as *Create Project* option.
* *Create Federation* - Create a new Federation.
* *Join Federation* - Join an existing Federation.
* *Fusion Project* - Create a new Fusion project.

image::media/web/new_project_types.png[title='Project Options', width=25%]


[[projects-advanced]]
==== Advanced Project Features

Advanced project features allow you to augment the standard learning behaviour for a project. The advanced options
are available on the last panel of the project wizard.
This augmentation can be as simple as performing dynamic data augmentation, such as the case with <<power-projects>> option,
or it could allow you to build online models such as <<rf-projects>> or <<km-projects>>

image::media/web/p_advanced.png[title='Advanced Options', width=50%]
{nbsp} +

[[power-projects]]
===== Power Transformation

Enabling power transformation when creating a project allows for the creation of power
regression models. See <<power-transformation>>.

image::media/web/p_advanced_pt.png[title='Advanced Options', width=50%]
{nbsp} +

When the *Power Transformation* option is selected, the user can specify the range of powers which will be
used to transform your target of choice.

In the figure above, we can see that column *y* has been chosen as a candidate for the power transformation.
The range of powers that will be created start at *-2* and go up to *2* using five evenly spaced intervals.

[[rf-projects]]
===== Random Forest

Random Forest can be enabled by the selecting the corresponding option in *Advanced Project Options* dropdown.
The required fields when selecting this option are :

* RF Classifier - *RF Type*, *Target Column* and *Number of Classes*
* RF Regressor - *RF Type* and *Target Column*
* RF Anomaly - *RF Type*

The inputs of the model can also be specified. If left unselected all of the inputs will be used.

image::media/web/rf_classifier.png[title='Advanced Options - RF Classifier', width=50%]

image::media/web/rf_regressor.png[title='Advanced Options - RF Regressor', width=50%]

image::media/web/rf_anomaly.png[title='Advanced Options - RF Anomaly', width=50%]
{nbsp}

Clicking *Finish* will start the project learn and fit the RF model.

After the project has finished learning, the final steps in creating the RF model involves:

1. Right clicking on the *Exploration* icon, and selecting *Random Forest* from the *Create Model* menu.

image::media/web/rf0.png[title='Create RF Menu', width=50%]
{nbsp}
2. Giving your model a name.

image::media/web/rf1.png[title='RF Build Model', width=50%]
{nbsp}
3. Clicking *Build Model* button.

[[km-projects]]
===== Kaplan-Meier

To enable Kaplan-Meier model, the corresponding option needs to be selected in *Advanced Project Options* dropdown.

The required fields when selecting this option are : *Time Column*, *Event Column* and *Group Column*

image::media/web/p_advanced_km.png[title='Advanced Options - RF', width=50%]

Clicking *Finish* will start the project learn and fit the KM model.

After the project has finished learning, build the KM model by:

1. Right clicking on the *Exploration* icon, and selecting *Kaplan-Meier* from the *Create Model* menu.
+
image::media/web/km0.png[title='Create KM Menu', width=50%]

2. Giving your model a name.
+
image::media/web/km1.png[title='KM Build Model', width=50%]

3. Clicking *Build Model* button.


[[creating-new-fed-projects]]
==== Federated Projects

Federated projects allow you to create a collaborative network of SymetryML nodes
which leverage external data while  preserving data privacy. A full tutorial of Federated Learning
can be found in the following section: <<./SML_FedML_User_Guide.adoc, FedML User Guide>>

[[creating-new-fusion-projects]]
==== Fusion Projects

Creating a Fusion project is a slightly different process than creating a local project.
Because fusion project does not learn any data itself and only amalgamates information from other projects,
it is important to know the host address and the user credentials for the SymetryML nodes that contain the actual source projects.

To begin creating the Fusion project:

1. Click *Fusion Project* in the project type selection dropdown menu.
+
image::media/web/create_fusion_1.png[title='Type Selection', width=25%]

2. Set your fusion *Project Name*
3. Fill out the *Host*, *User ID*, *User Secret Key*, and *Project Name* of your cell project.
4. Click *Add*
5. Repeat Step 3 and 4 for any additional cell you wish to include.
6. Click *Validate* to ensure that the fusion cells are accessible.
+
image::media/web/create_fusion_3.png[title='Fusion Cells', width=50%]
7. Finally, click "Create" to complete the process.

Should you need to edit the information in your Fusion project, you can simply
right click on the *Fusion* node and click *Fusion Info*

image::media/web/update_fusion_1.png[title='Update Fusion Info', width=25%]
{nbsp} +

From here you are able to add and remove cells as you see fit.

image::media/web/update_fusion_2.png[title='Update Fusion', width=50%]


[[exploring-projects]]
==== Exploring Projects

After you create your project, you can access multiple forms of
univariate and bivariate methods of analysis.

1.  Double-click the *Exploration* icon in the project tree.
2.  Click the tab corresponding to the task you want to perform.

[[adding-data-to-projects]]
==== Adding Data to Projects

You can augment an existing project with additional data at a later
time. For example, you can use this feature with an output of a weekly
ETL process that constantly updates the file for use within SymetryML.

1.  Right-click the *Exploration* node of your project tree.
2.  Click *Add Data.*
+
image::media/web/sml_add_data.png[title='Project Tree Add Data', width=25%]
{nbsp} +

3.  Specify whether you are using an existing or new data source, and
then click *Next* to continue.
4.  Inspect your data to ensure it was read properly. Click *Next* to
add the data to your project.

[[learning-and-forgetting]]
==== Learning and Forgetting

After you add a new data source to your project, you can either learn
from this data or forget the records.

* To learn a newly added data source, right-click the data-source node
in the project tree, and then click *Learn*.

image::media/web/sml_learn.png[title='Project Tree Learn', width=25%]

* To forget a data source, right-click the data source node in the
project tree, and then click *Forget*.

image::media/web/sml_forget.png[title='Project Tree Forget', width=25%]

[[update-log]]
==== Update Log

All the data source updates to a project are tracked in the Update Log.
Here you can see the number of records processed for each data source and the time
it took to process them.

Update Log can be displayed by right clicking on the *Exploration* node and selecting *Update Log*.

image::media/web/update_log_menu.png[title='Update Log', width=25%]

image::media/web/update_log_result.png[title='Update Log Result', width=50%]

[[renaming-projects]]
==== Renaming Projects

You can rename a project at any time.

1.  Expand the *Projects* accordion. Right-click the exploration node,
and then click **Rename Project**.
2.  Enter the new name, and then click *OK* when finished.

[[merge-projects]]
==== Merging Projects

Two projects can be merged. This process involves transferring all the learned data
from the source project into a destination project. To perform a project merge:

1.  Right click on the destination project icon.
+
image::media/web/merge_project_1.png[title='Merge Project', width=25%]

2.  Select **Merge Project** from the contextual menu.
3.  After the *Merge Project* wizard appears, select the source project.
+
image::media/web/merge_project_2.png[title='Merge Project Select', width=50%]

4.  Click **Finish**

The destination project will now be updated with the metadata of the source project.

[[deleting-projects]]
==== Deleting Projects

If you no longer need a project, you can delete it. When you delete a
project, all accumulated metadata and models related to the project are
also deleted. However, associated data sources and encoders will still
be available.

1.  Expand the *Projects* accordion. Right-click the project node, and
then click **Delete**.

[[freezing-projects]]
==== Freezing Projects

Project state can also be temporarily frozen. This prevents the project from performing
any additional learning or forgetting. Once it is deemed necessary to revert to the standard
learn/forget behaviour, a project can be unfrozen.

image::media/web/project_freeze.png[title='Freeze Project', width=25%]
{nbsp} +

image::media/web/project_unfreeze.png[title='Unfreeze Project', width=25%]


[[sync-project]]
==== Sync Project

Because a SymetryML project can be altered in both GUI and via a REST API call, it is often beneficial to
synchronize your project. This action ensures that the representation of the project on the SymetryML server
aligns with what the user sees in the Web UI.

image::media/web/project_sync.png[title='Project Sync', width=25%]

[[detaching-data]]
==== Detaching Data

Data can be detached from a given project. Note, this will not “unlearn”
the data source. It simply disassociates the data from the project.

image::media/web/sml_detach.png[title='Data Detach', width=25%]

[[managing-memory]]
==== Managing Memory

SymetryML Projects are permanently persisted inside a fast access in-memory database. However, direct interaction with the Projects, either though learning, model building or prediction, requires the Project to be loaded into the memory of the JVM process.

Over time, as the number of projects grow, the physical memory of the machine hosting the SymetryML process will become exhausted. In this case, it becomes necessary to manually manage the memory consumption of the JVM process.

Within the SymetryML Web UI, you are able to unload the chosen project and reduce the physical memory requirements of the SymetryML process.

image::media/web/sml_unload.png[title='Unload Project', width=25%]
{nbsp} +

Unloaded project will be displayed as the lighter version of its in-memory counterparts.
Loading the project back into JVM memory can be performed by either double-clicking on the corresponding icon,
or right-clicking and selecting *Load Project*.

[[working-with-models]]
=== Working with Models

After you create a project, you can build models. Using models, you can
leverage the historical data learned within the project to make
predictions about the future.

[[creating-new-models-accordion]]
==== Creating New Models - Main Accordion

To create a new model:

1.  Right-click the *Exploration* icon in the project tree, and then
click the appropriate model for you needs.
+
image::media/web/project_create.png[title="Project Create Model", width=25%]
{nbsp} +
+
image::media/web/meta_model_create.png[title="Create Model - Partition Project", width=25%]
{nbsp} +
+
NOTE: Partitioned projects allow you to create two additional types of models:
MetaLDA and MetaQDA. For more information see
<<using-classification-models>>


2. Assign a new name to the model. Certain models allow for additional
options relating to feature selection and model
reduction . Furthermore, because these models rely heavily on
matrix inversion, the user is able to adjust the sensitivity of such
operations via Reciprocal Condition Number Threshold. Note, this feature is for advanced users only.
3.  Check the attributes you want to use as inputs and targets.
Click *Build Model* to continue.
+
image::media/web/model_type_classification.png[title='Model-Type Selection (Classification and Regression)', width=50%]
{nbsp} +
+
image::media/web/hmm_model_role_selection.png[title='Model-Role Selection (Sequence)', width=50%]
{nbsp} +

4.  After completing the model-building process, double click on the model icon to see
information about your new model.

// ==== Creating New Models - Exploration
// The *Exploration Panel* provides an alternative way of creating models

// image::media/web/explore_model_create.png[title='Model Create', width=50%]

// . Highlight the columns you wish to use as your input attributes.
// . Right-click on the contextual panel.
// . Select the appropriate model type

// NOTE: This option is only available in : *Univariate*, *Correlation*, *PCA*,
// *SVD*, and *Information Gain* panels

[[model-select]]
==== Model Select

When working with only a handful of attributes, creating models by manually specifying the
input attributes is often times sufficient to get an acceptable result.
However, as the number of attributes gets large, the choice
of which attributes to use can be aided by a model selection heuristic.

The model selection heuristic within SymetryML works as follows.
First, the user  has to decide on the general type of modeling that needs to be done, whether the task is Classification
or Regression. Then, an out of sample data file is provided. SymetryML uses this out of sample file
to test the various combinations of input attributes and select the one that provides the highest AUC, when dealing with classification,
or the lowest RMSE when dealing with Regression problems.

image::media/web/auto_select_0.png[title='Model Select - Specify Algorithm', width=25%]
{nbsp} +

If the user has a particular algorithm in mind, then the only choice left to be made is one regarding attributes and model hyperparameters.
This can be achieved by right clicking on the *Exploration* node picking *Select Model* , choosing *Regression* or *Classification* as
the task type and finally picking the model of your choosing.

However, if there are no strong preferences regarding the algorithm used, the user can simply use *Auto Select* option. This will
require specifying the task type *Binary Classification* or *Regression*. SymetryML would then cycle through the appropriate
algorithms for the task and pick their hyperparameters accordingly.

image::media/web/auto_select_1.png[title='Model Select - Specify Task Type', width=50%]
{nbsp} +

For more information detailing the *Search Heuristic* and the *Search Space* see section on <<selecting-models>>

[[clone-model]]
==== Clone Model

Models within a particular class (i.e., Classification or Regression)
can be cloned, rebuilt, with a different algorithm by simply selecting
the preferred algorithm within the model info view.

image::media/web/model_clone.png[title='Model Clone', width=25%]

[[sequence-models]]
==== Sequence Models

Sequence models, unlike their classification and regression
counterparts, require the project to be constructed as a sequence
project from the start.

[[viewing-model-metadata]]
==== Viewing Model Metadata

Once the model is built, you can double click on the corresponding model
icon in the projects view and see the associated metadata.

The type of information displayed is dependent on the class of model.

image::media/web/linear_model.png[title='Linear Model Metadata', width=100%]
{nbsp} +

image::media/web/hmm_meta_data.png[title='HMM Model Metadata', width=100%]
{nbsp} +

image::media/web/mc_meta_data.png[title='MC Model Metadata', width=100%]

[[refining-lda-models]]
==== Refining LDA Models

LDA models have a special property that differentiates them from other
algorithms. They can be refined, or updated, in real time. This means
you can add or remove attributes as you see fit and the model will be
rebuilt instantly. To refine a model, select the *Input Attributes* you
want to add and remove the ones you want to remove.

image::media/web/refine_model.png[title='Example of Refining a Model', width=100%]

[[deleting-models]]
==== Deleting Models

To remove a model:

1.  Right-click the model node, and then click *Delete Model*.
+
image::media/web/delete_model.png[title='Deleting a Model', width=25%]

[[assessing-model-performance]]
==== Assessing Model Performance

You can assess the performance of most models (excluding MC) using a
labeled file.

1.  Right-click the model node, and then click *Assessment*.
+
image::media/web/project_assessment.png[title='Project Assessment', width=25%]

2.  Specify the input data source you will use for the assessment, and
then click *Next* to continue.
3.  Verify the data source you added, and then click *Next* to continue.
4.  Ensure that your model’s target variables are mapped to the target
variables of your file.
+
image::media/web/new_assessment.png[title='New Assessment', width=25%]

5.  Click *Finish* to start the assessment process.
6.  After the assessment process finishes, a dialog box asks whether you
want to see the assessment results. If you click **Yes**, the assessment
information panel appropriate for your model type appears (see the
following figures).

* Simple binary classification models show a confusion matrix with lift
curve information.
* Regression models show a distribution of errors curve in addition to
RMSE and MAE.
* Multi-target classification models show a descriptive confusion
matrix.
+
image::media/web/assessment_binary.png[title='Binary Target Assessment', width=50%]
{nbsp} +
+
image::media/sequence/sml_hmm_assess_5.png[title="Assessment Result", image,width=50%]
{nbsp} +
+
image::media/web/assessment_regression.png[title='Regression Assessment', width=50%]
{nbsp} +

[[exporting-models]]
==== Export/Import Models

Once built, a model can be exported out of a project and later imported into a different project.
This allows for workflows in which a production environment can be completely separate from a development environment
while this levering models build in the latter.

image::media/web/model_export.png[title='Model Export', width=25%]
{nbsp} +

image::media/web/model_import.png[title='Model Import', width=25%]
{nbsp} +

image::media/web/model_select.png[title='Model Import - File Select', width=50%]
{nbsp} +

[[using-a-model-for-predictions]]
==== Using a Model for Predictions

In addition to performing an assessment, you can use an existing model
for predictions against a file.

1.  Right-click the model node, and then click *Predict*.
+
image::media/web/predict_preview.png[title='Predict', width=25%]
{nbsp} +

2.  Specify the input data source, and then click *Next* to continue.
3.  Specify the output data source, which is the location where you want
your predictions saved. Click *Next* to continue. A preview of the input
data source appears.
4.  Verify that the data source has been read correctly, and then click
*Next* to continue.
5.  Ensure the types in the data source match those of the model. Click
*Next* to continue.
6.  After the prediction process completes, a sample of the prediction
result appears. To download the entire prediction file, click the
*Download* button.
+
image::media/web/prediction_export.png[title='Prediction Export', width=100%]
